# Auto-generated by Manus: Chaos Triage Arena scaffold

import time
import threading
import random
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import uvicorn
import requests
import psutil
import os


class FailureRequest(BaseModel):
    type: str


class StressRequest(BaseModel):
    intensity: int = 50


class MemoryRequest(BaseModel):
    size_mb: int = 100


class LatencyRequest(BaseModel):
    latency_ms: int = 0


class BaseService:
    def __init__(self, name: str, port: int, dependencies: list = None):
        self.name = name
        self.port = port
        self.dependencies = dependencies or []
        self.app = FastAPI(title=f"{name} Service")
        
        # Service state
        self.is_failed = False
        self.failure_type = None
        self.artificial_latency = 0
        self.cpu_stress_active = False
        self.memory_leak_data = []
        
        # Setup routes
        self._setup_routes()
        
        # Start background tasks
        self._start_background_tasks()
    
    def _setup_routes(self):
        @self.app.get("/healthz")
        async def healthz():
            if self.is_failed:
                raise HTTPException(status_code=503, detail=f"Service failed: {self.failure_type}")
            return {"status": "healthy", "service": self.name}
        
        @self.app.get("/status")
        async def status():
            return {
                "service": self.name,
                "status": "failed" if self.is_failed else "healthy",
                "failure_type": self.failure_type,
                "port": self.port,
                "dependencies": self.dependencies
            }
        
        @self.app.get("/metrics")
        async def metrics():
            process = psutil.Process()
            return {
                "service": self.name,
                "cpu_percent": process.cpu_percent(),
                "memory_mb": process.memory_info().rss / 1024 / 1024,
                "timestamp": time.time(),
                "artificial_latency": self.artificial_latency,
                "is_failed": self.is_failed,
                "failure_type": self.failure_type,
                "cpu_stress_active": self.cpu_stress_active,
                "memory_leak_size": len(self.memory_leak_data)
            }
        
        @self.app.get("/logs")
        async def logs():
            # Simple log endpoint - in real service this would return actual logs
            return {
                "service": self.name,
                "recent_logs": [
                    f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Service {self.name} is running",
                    f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] Health status: {'failed' if self.is_failed else 'healthy'}"
                ]
            }
        
        @self.app.post("/fail")
        async def fail(request: FailureRequest):
            self.is_failed = True
            self.failure_type = request.type
            return {"ok": True, "message": f"Injected failure: {request.type}"}
        
        @self.app.post("/recover")
        async def recover():
            self.is_failed = False
            self.failure_type = None
            self.artificial_latency = 0
            self.cpu_stress_active = False
            self.memory_leak_data.clear()
            return {"ok": True, "message": "Service recovered"}
        
        @self.app.post("/stress/cpu")
        async def stress_cpu(request: StressRequest):
            self.cpu_stress_active = True
            # Start CPU stress in background
            threading.Thread(target=self._cpu_stress_worker, args=(request.intensity,), daemon=True).start()
            return {"ok": True, "intensity": request.intensity}
        
        @self.app.post("/stress/memory")
        async def stress_memory(request: MemoryRequest):
            # Allocate memory
            chunk_size = 1024 * 1024  # 1MB chunks
            for _ in range(request.size_mb):
                self.memory_leak_data.append(b'x' * chunk_size)
            return {"ok": True, "allocated_mb": request.size_mb}
        
        @self.app.post("/config/latency")
        async def config_latency(request: LatencyRequest):
            self.artificial_latency = request.latency_ms
            return {"ok": True, "latency_ms": request.latency_ms}
    
    def _cpu_stress_worker(self, intensity: int):
        """Background CPU stress worker"""
        duration = 30  # Run for 30 seconds
        end_time = time.time() + duration
        
        while time.time() < end_time and self.cpu_stress_active:
            # Busy work proportional to intensity
            work_time = intensity / 100.0 * 0.1  # Max 0.1 seconds of work
            sleep_time = 0.1 - work_time
            
            start = time.time()
            while time.time() - start < work_time:
                _ = sum(i * i for i in range(1000))
            
            if sleep_time > 0:
                time.sleep(sleep_time)
        
        self.cpu_stress_active = False
    
    def _start_background_tasks(self):
        """Start background monitoring tasks"""
        def latency_injector():
            while True:
                if self.artificial_latency > 0:
                    time.sleep(self.artificial_latency / 1000.0)
                time.sleep(0.1)
        
        threading.Thread(target=latency_injector, daemon=True).start()
    
    def call_dependency(self, service_name: str, endpoint: str = "/healthz"):
        """Call a dependency service"""
        # This would normally use service discovery, but for demo we use fixed ports
        service_ports = {
            "api_gateway": 8001,
            "database_service": 8002,
            "user_service": 8003,
            "payment_service": 8004,
            "echo_service": 8005
        }
        
        if service_name not in service_ports:
            raise HTTPException(status_code=500, detail=f"Unknown dependency: {service_name}")
        
        port = service_ports[service_name]
        try:
            response = requests.get(f"http://127.0.0.1:{port}{endpoint}", timeout=5)
            return response.json()
        except Exception as e:
            raise HTTPException(status_code=503, detail=f"Dependency {service_name} unavailable: {str(e)}")
    
    def run(self):
        """Run the service"""
        print(f"Starting {self.name} service on port {self.port}")
        uvicorn.run(self.app, host="127.0.0.1", port=self.port, log_level="warning")

