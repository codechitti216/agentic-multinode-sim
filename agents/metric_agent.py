# Auto-generated by Manus: Chaos Triage Arena scaffold

import json
import time
import argparse
import sys
from fastapi import FastAPI
import uvicorn
import requests
import psutil


class MetricAgent:
    """Agent for collecting and analyzing performance metrics"""
    
    def __init__(self, port: int):
        self.port = port
        self.app = FastAPI(title="MetricAgent")
        self.setup_routes()
    
    def setup_routes(self):
        @self.app.post("/run")
        async def run_analysis(step_data: dict):
            """Execute metrics analysis step"""
            try:
                result = self.analyze_metrics(step_data)
                return {"success": True, "result": result}
            except Exception as e:
                return {"success": False, "error": str(e)}
    
    def analyze_metrics(self, step_data: dict) -> dict:
        """Analyze metrics for the target service"""
        target_service = step_data.get("target_service", "unknown")
        step_type = step_data.get("step", "check_metrics")
        
        analysis_result = {
            "service": target_service,
            "step": step_type,
            "timestamp": time.time(),
            "system_metrics": {},
            "service_metrics": {},
            "alerts": [],
            "recommendations": []
        }
        
        # Collect system-wide metrics
        try:
            analysis_result["system_metrics"] = {
                "cpu_percent": psutil.cpu_percent(interval=1),
                "memory_percent": psutil.virtual_memory().percent,
                "disk_percent": psutil.disk_usage('/').percent,
                "load_average": psutil.getloadavg() if hasattr(psutil, 'getloadavg') else [0, 0, 0]
            }
        except Exception as e:
            analysis_result["alerts"].append(f"Failed to collect system metrics: {e}")
        
        # Try to get service-specific metrics
        service_ports = {
            "api_gateway": 8001,
            "database_service": 8002,
            "user_service": 8003,
            "payment_service": 8004,
            "echo_service": 8005
        }
        
        if target_service in service_ports:
            port = service_ports[target_service]
            try:
                response = requests.get(f"http://127.0.0.1:{port}/metrics", timeout=5)
                if response.status_code == 200:
                    analysis_result["service_metrics"] = response.json()
                else:
                    analysis_result["alerts"].append(f"Service metrics endpoint returned {response.status_code}")
            except Exception as e:
                analysis_result["alerts"].append(f"Failed to collect service metrics: {e}")
        
        # Analyze metrics and generate alerts
        system_metrics = analysis_result["system_metrics"]
        service_metrics = analysis_result["service_metrics"]
        
        # System-level alerts
        if system_metrics.get("cpu_percent", 0) > 80:
            analysis_result["alerts"].append("High system CPU usage detected")
            analysis_result["recommendations"].append("Consider reducing system load or scaling resources")
        
        if system_metrics.get("memory_percent", 0) > 85:
            analysis_result["alerts"].append("High system memory usage detected")
            analysis_result["recommendations"].append("Check for memory leaks or increase available memory")
        
        if system_metrics.get("disk_percent", 0) > 90:
            analysis_result["alerts"].append("High disk usage detected")
            analysis_result["recommendations"].append("Clean up disk space or expand storage")
        
        # Service-level alerts
        if service_metrics:
            service_cpu = service_metrics.get("cpu_percent", 0)
            service_memory = service_metrics.get("memory_mb", 0)
            is_failed = service_metrics.get("is_failed", False)
            artificial_latency = service_metrics.get("artificial_latency", 0)
            
            if is_failed:
                analysis_result["alerts"].append(f"Service {target_service} is in failed state")
                analysis_result["recommendations"].append("Execute service recovery procedure")
            
            if service_cpu > 70:
                analysis_result["alerts"].append(f"High CPU usage in {target_service}: {service_cpu}%")
                analysis_result["recommendations"].append("Check for CPU-intensive operations or infinite loops")
            
            if service_memory > 300:  # 300MB threshold
                analysis_result["alerts"].append(f"High memory usage in {target_service}: {service_memory}MB")
                analysis_result["recommendations"].append("Check for memory leaks or optimize memory usage")
            
            if artificial_latency > 100:
                analysis_result["alerts"].append(f"Artificial latency detected in {target_service}: {artificial_latency}ms")
                analysis_result["recommendations"].append("Remove artificial latency configuration")
            
            if service_metrics.get("cpu_stress_active", False):
                analysis_result["alerts"].append(f"CPU stress test active in {target_service}")
                analysis_result["recommendations"].append("Stop CPU stress test")
            
            if service_metrics.get("memory_leak_size", 0) > 0:
                analysis_result["alerts"].append(f"Memory leak detected in {target_service}")
                analysis_result["recommendations"].append("Restart service to clear memory leak")
        
        # Performance analysis
        if not analysis_result["alerts"]:
            analysis_result["recommendations"].append("Metrics appear normal - no immediate action required")
        
        # Add trend analysis (simplified)
        analysis_result["trend_analysis"] = {
            "cpu_trend": "stable",  # Would be calculated from historical data
            "memory_trend": "stable",
            "performance_score": max(0, 100 - len(analysis_result["alerts"]) * 20)
        }
        
        return analysis_result
    
    def run(self):
        """Run the MetricAgent server"""
        print(f"MetricAgent starting on port {self.port}")
        uvicorn.run(self.app, host="127.0.0.1", port=self.port, log_level="warning")


def main():
    parser = argparse.ArgumentParser(description="MetricAgent - Performance metrics analysis")
    parser.add_argument("--port", type=int, required=True, help="Port to listen on")
    parser.add_argument("--step-data", type=str, help="JSON step data")
    
    args = parser.parse_args()
    
    # If step-data provided, run once and exit
    if args.step_data:
        try:
            step_data = json.loads(args.step_data)
            agent = MetricAgent(args.port)
            result = agent.analyze_metrics(step_data)
            print(json.dumps(result))
            sys.exit(0)
        except Exception as e:
            print(json.dumps({"success": False, "error": str(e)}))
            sys.exit(1)
    
    # Otherwise run as server
    agent = MetricAgent(args.port)
    agent.run()


if __name__ == "__main__":
    main()

